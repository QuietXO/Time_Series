{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **_Time Series Prediction ([Concept](https://www.sciencedirect.com/science/article/abs/pii/S1568494622000217))_**\n",
    "### __*Interpretable cognitive learning with spatial attention for high-volatility time series prediction*__\n",
    "__*[A short tutorial on Fuzzy Time Series](https://towardsdatascience.com/a-short-tutorial-on-fuzzy-time-series-dcc6d4eb1b15)*__\n",
    "__*[A short tutorial on Fuzzy Time Series — Part II](https://towardsdatascience.com/a-short-tutorial-on-fuzzy-time-series-part-ii-with-an-case-study-on-solar-energy-bda362ecca6d)*__\n",
    "__*[A short tutorial on Fuzzy Time Series — Part III](https://towardsdatascience.com/a-short-tutorial-on-fuzzy-time-series-part-iii-69445dff83fb)*__\n",
    "__*[Causal Inference: an Overview](https://towardsdatascience.com/causal-inference-an-overview-736efdfe01c4)*__\n",
    "__*[Causal Forecasting at Lyft (Part 2)](https://medium.com/lyft-engineering/causal-forecasting-at-lyft-part-2-418f1febca5a)*__\n",
    "__*[Building a large scale unsupervised model anomaly detection system — Part 1](https://eng.lyft.com/building-a-large-scale-unsupervised-model-anomaly-detection-system-part-1-aca4766a823c)*__\n",
    "__*[Building a large scale unsupervised model anomaly detection system — Part 2](https://eng.lyft.com/building-a-large-scale-unsupervised-model-anomaly-detection-system-part-2-3690f4c37c5b)*__\n",
    "__*[A Crash Course in Causality](https://medium.com/geekculture/notes-a-crash-course-in-causality-week-1-f77bd9ef61cb)*__\n",
    "__*[Causal Python — Level Up Your Causal Discovery Skills in Python](https://towardsdatascience.com/beyond-the-basics-level-up-your-causal-discovery-skills-in-python-now-2023-cabe0b938715)*__\n",
    "__*[Six Causality Books That Will Get You From Zero to Advanced](https://aleksander-molak.medium.com/yes-six-causality-books-that-will-get-you-from-zero-to-advanced-2023-f4d08718a2dd)*__\n",
    "__*[Modeling uncertainty in neural networks](https://towardsdatascience.com/modeling-uncertainty-in-neural-networks-with-tensorflow-probability-part-1-an-introduction-2bb564c67d6)*__\n",
    "__*[Predicting Daily Air Pollution Index Based on Fuzzy Time Series Markov Chain Model](https://www.mdpi.com/2073-8994/12/2/293)*__\n",
    "__*[]()*__\n",
    "__*[]()*__\n",
    "__*[]()*__\n",
    "__*[]()*__\n",
    "__*[]()*__\n",
    "__*[]()*__\n",
    "__*[]()*__\n",
    "__*[]()*__\n",
    "__*[]()*__\n",
    "__*[]()*__\n",
    "__*[]()*__\n",
    "__*[]()*__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "### __*Import Libraries*__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pyFTS\n",
    "import math\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "### __*Fuzzy Time Series Prediction Model*__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "### __*Preparation of the [Google Stock Price](https://www.kaggle.com/datasets/e7c33ac54ade05be32a190e20c1dc176f268acbd28c22d28900e96112383b18e) Data*__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# # Show structure of dataset\n",
    "# goog_raw = pd.read_csv('data/GOOG.csv')\n",
    "# goog_raw.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# # Import the required libraries\n",
    "# from pyFTS.models import hofts\n",
    "# from pyFTS.partitioners import Grid\n",
    "#\n",
    "# # Load the dataset\n",
    "# data = goog_raw['close']\n",
    "#\n",
    "# # Set the number of lags for the model\n",
    "# num_lags = 5\n",
    "#\n",
    "# # Split the dataset into training and testing sets\n",
    "# train_data = data.iloc[:1020]\n",
    "# test_data = data.iloc[1020:]\n",
    "#\n",
    "# # Define the partitioner\n",
    "# part = Grid.GridPartitioner(data=train_data, npart=200)\n",
    "#\n",
    "# # Create the high order FTS model\n",
    "# model = hofts.HighOrderFTS(data=train_data.values, partitioner=part, order=num_lags)\n",
    "#\n",
    "# # Train the model\n",
    "# model.fit(train_data.values)\n",
    "#\n",
    "# # Use the model to predict the test data\n",
    "# forecast = model.predict(test_data.values)\n",
    "#\n",
    "# # Truncate the test data to match the length of the predicted data\n",
    "# test_data_truncated = test_data.iloc[num_lags-1:-1]\n",
    "#\n",
    "# # Calculate the RMSE\n",
    "# rmse = math.sqrt(mean_squared_error(test_data_truncated.values, forecast))\n",
    "#\n",
    "# # Calculate the MAPE\n",
    "# mape = (abs((test_data_truncated.values - forecast) / test_data_truncated.values)).mean() * 100\n",
    "#\n",
    "# # Print the error metrics\n",
    "# print('RMSE:', rmse)\n",
    "# print('MAPE:', mape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# # Plot the actual vs predicted data\n",
    "# plt.plot(test_data_truncated.values, label='Actual')\n",
    "# plt.plot(forecast, label='Predicted')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# from pyFTS.data import Enrollments\n",
    "#\n",
    "# # Load the dataset\n",
    "# data = pd.read_csv('data/GOOG.csv')\n",
    "# data = data['close']\n",
    "#\n",
    "# train_data = data.iloc[:1000].to_numpy()\n",
    "# test_data = data.iloc[1000:].to_numpy()\n",
    "#\n",
    "# from pyFTS.partitioners import Grid, Entropy, Util as pUtil\n",
    "# fs = Grid.GridPartitioner(data=train_data, npart=200)\n",
    "#\n",
    "# from pyFTS.models import chen\n",
    "# model = chen.ConventionalFTS(partitioner=fs)\n",
    "# model.fit(train_data)\n",
    "# forecasts = model.predict(test_data)\n",
    "#\n",
    "# # Truncate the test data to match the length of the predicted data\n",
    "# test_data_truncated = test_data\n",
    "#\n",
    "# # Calculate the RMSE\n",
    "# rmse = math.sqrt(mean_squared_error(test_data_truncated, forecasts))\n",
    "#\n",
    "# # Calculate the MAPE\n",
    "# mape = (abs((test_data_truncated - forecasts) / test_data_truncated)).mean() * 100\n",
    "#\n",
    "# # Print the error metrics\n",
    "# print('RMSE:', rmse)\n",
    "# print('MAPE:', mape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# # Plot the actual vs predicted data\n",
    "# plt.plot(test_data_truncated, label='Actual')\n",
    "# plt.plot(forecasts, label='Predicted')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "### __*Preparation of the [Weather](https://www.kaggle.com/datasets/ananthr1/weather-prediction) Data*__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "         date  precipitation  temp_max  temp_min  wind  weather\n0  2012-01-01            0.0      12.8       5.0   4.7  drizzle\n1  2012-01-02           10.9      10.6       2.8   4.5     rain\n2  2012-01-03            0.8      11.7       7.2   2.3     rain\n3  2012-01-04           20.3      12.2       5.6   4.7     rain\n4  2012-01-05            1.3       8.9       2.8   6.1     rain",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>precipitation</th>\n      <th>temp_max</th>\n      <th>temp_min</th>\n      <th>wind</th>\n      <th>weather</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2012-01-01</td>\n      <td>0.0</td>\n      <td>12.8</td>\n      <td>5.0</td>\n      <td>4.7</td>\n      <td>drizzle</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2012-01-02</td>\n      <td>10.9</td>\n      <td>10.6</td>\n      <td>2.8</td>\n      <td>4.5</td>\n      <td>rain</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2012-01-03</td>\n      <td>0.8</td>\n      <td>11.7</td>\n      <td>7.2</td>\n      <td>2.3</td>\n      <td>rain</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2012-01-04</td>\n      <td>20.3</td>\n      <td>12.2</td>\n      <td>5.6</td>\n      <td>4.7</td>\n      <td>rain</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2012-01-05</td>\n      <td>1.3</td>\n      <td>8.9</td>\n      <td>2.8</td>\n      <td>6.1</td>\n      <td>rain</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show structure of dataset\n",
    "weather_raw = pd.read_csv('data/seattle-weather.csv')\n",
    "weather_raw.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0       12.8\n",
      "1       10.6\n",
      "2       11.7\n",
      "3       12.2\n",
      "4        8.9\n",
      "        ... \n",
      "1456     4.4\n",
      "1457     5.0\n",
      "1458     7.2\n",
      "1459     5.6\n",
      "1460     5.6\n",
      "Name: temp_max, Length: 1461, dtype: float64, 0       5.0\n",
      "1       2.8\n",
      "2       7.2\n",
      "3       5.6\n",
      "4       2.8\n",
      "       ... \n",
      "1456    1.7\n",
      "1457    1.7\n",
      "1458    0.6\n",
      "1459   -1.0\n",
      "1460   -2.1\n",
      "Name: temp_min, Length: 1461, dtype: float64]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [51]\u001B[0m, in \u001B[0;36m<cell line: 13>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     10\u001B[0m num_lags \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# Split the dataset into training and testing sets\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m train_data \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m[:\u001B[38;5;241m1200\u001B[39m]\u001B[38;5;241m.\u001B[39mto_numpy()\n\u001B[0;32m     14\u001B[0m test_data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m1200\u001B[39m:]\u001B[38;5;241m.\u001B[39mto_numpy()\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# Define the partitioner\u001B[39;00m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'list' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "# Import the required libraries\n",
    "from pyFTS.models import hofts\n",
    "from pyFTS.partitioners import Grid\n",
    "\n",
    "# Load the dataset\n",
    "data = weather_raw['temp_max']\n",
    "print(data)\n",
    "\n",
    "# Set the number of lags for the model\n",
    "num_lags = 10\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_data = data.iloc[:1200].to_numpy()\n",
    "test_data = data.iloc[1200:].to_numpy()\n",
    "\n",
    "# Define the partitioner\n",
    "part = Grid.GridPartitioner(data=train_data, npart=200)\n",
    "\n",
    "# Create the high order FTS model\n",
    "model = hofts.HighOrderFTS(data=train_data, partitioner=part, order=num_lags)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data)\n",
    "\n",
    "# Use the model to predict the test data\n",
    "forecast = model.predict(test_data)\n",
    "# print(model.predict([8.9, 8.3, 8.9, 10.0, 6.7, 6.7, 7.2, 9.4, 9.4, 7.2]))  # 1.7 5.6\n",
    "\n",
    "# Truncate the test data to match the length of the predicted data\n",
    "test_data_truncated = test_data[num_lags-1:-1]\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmse = math.sqrt(mean_squared_error(test_data_truncated, forecast))\n",
    "\n",
    "# Calculate the MAPE\n",
    "test_data_truncated_mape = list(test_data_truncated)\n",
    "forecast_mape = list(forecast)\n",
    "\n",
    "for idx in range(len(test_data_truncated)):\n",
    "    if test_data_truncated[idx] == 0:\n",
    "        test_data_truncated_mape[idx] = 1\n",
    "        forecast_mape[idx] = 1\n",
    "\n",
    "test_data_truncated_mape = np.array(test_data_truncated_mape)\n",
    "forecast_mape = np.array(forecast_mape)\n",
    "\n",
    "mape = (abs((test_data_truncated_mape - forecast_mape) / test_data_truncated_mape)).mean() * 100\n",
    "\n",
    "# Print the error metrics\n",
    "print('RMSE:', rmse)\n",
    "print('MAPE:', mape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the actual vs predicted data\n",
    "plt.plot(test_data_truncated, label='Actual')\n",
    "plt.plot(forecast, label='Predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyFTS.data import Enrollments\n",
    "\n",
    "# Load the dataset\n",
    "data = weather_raw['temp_min']\n",
    "\n",
    "train_data = data.iloc[:1200].to_numpy()\n",
    "test_data = data.iloc[1200:].to_numpy()\n",
    "\n",
    "from pyFTS.partitioners import Grid, Entropy, Util as pUtil\n",
    "fs = Grid.GridPartitioner(data=train_data, npart=200)\n",
    "\n",
    "from pyFTS.models import chen\n",
    "model = chen.ConventionalFTS(partitioner=fs)\n",
    "model.fit(train_data)\n",
    "forecasts = np.array(model.predict(test_data))\n",
    "print(model.predict([8.9]))\n",
    "\n",
    "# Truncate the test data to match the length of the predicted data\n",
    "test_data_truncated = test_data\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmse = math.sqrt(mean_squared_error(test_data_truncated, forecasts))\n",
    "\n",
    "# Calculate the MAPE\n",
    "test_data_truncated_mape = list(test_data_truncated)\n",
    "forecast_mape = list(forecasts)\n",
    "for idx in range(len(test_data_truncated)):\n",
    "    if test_data_truncated[idx] == 0:\n",
    "        test_data_truncated_mape[idx] = 1\n",
    "        forecast_mape[idx] = 1\n",
    "\n",
    "test_data_truncated_mape = np.array(test_data_truncated_mape)\n",
    "forecast_mape = np.array(forecast_mape)\n",
    "\n",
    "mape = (abs((test_data_truncated_mape - forecast_mape) / test_data_truncated_mape)).mean() * 100\n",
    "\n",
    "# Print the error metrics\n",
    "print('RMSE:', rmse)\n",
    "print('MAPE:', mape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the actual vs predicted data\n",
    "plt.plot(test_data_truncated, label='Actual')\n",
    "plt.plot(forecasts, label='Predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
